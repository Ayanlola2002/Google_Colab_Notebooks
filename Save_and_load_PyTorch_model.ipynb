{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save and load PyTorch model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Google_Colab_Notebooks/blob/master/Save_and_load_PyTorch_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2eb-DdE08VLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Created by Paul A. Gureghian on 11/28/18.**\n",
        "\n",
        "**This notebook contains a blueprint for,**\n",
        "\n",
        "**saving and loading PyTorch models.**"
      ]
    },
    {
      "metadata": {
        "id": "AKC699DV7yyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Install CUDA driver\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1apreKz0G81O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import packages\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import  datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CdYBgalHntu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08AhbiAZHvWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-Jz8p4FHeJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### ### Download and load the testing data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSSBe0QZOJ_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0raUHHkUNzIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "87b8a185-3107-4df2-e56f-750bfc931313"
      },
      "cell_type": "code",
      "source": [
        "### View one of the images \n",
        "image, label = next(iter(trainloader))\n",
        "imshow(image[0,:]);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa16a1563c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tjYyd5_OOhbk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input layer\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "        \n",
        "        '''\n",
        "        super().__init__()\n",
        "        # Input to a hidden layer\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "        \n",
        "        # Add a variable number of more hidden layers\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "        \n",
        "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=drop_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krI_0Kh1OoJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Create a network with hyperparams and metrics\n",
        "model = Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcrtrNMvQ9cR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
        "    \n",
        "    steps = 0\n",
        "    running_loss = 0\n",
        "    for e in range(epochs):\n",
        "        # Model in training mode, dropout is on\n",
        "        model.train()\n",
        "        for images, labels in trainloader:\n",
        "            steps += 1\n",
        "            \n",
        "            # Flatten images into a 784 long vector\n",
        "            images.resize_(images.size()[0], 784)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if steps % print_every == 0:\n",
        "                # Model in inference mode, dropout is off\n",
        "                model.eval()\n",
        "                \n",
        "                # Turn off gradients for validation, will speed up inference\n",
        "                with torch.no_grad():\n",
        "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
        "                \n",
        "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "                \n",
        "                running_loss = 0\n",
        "                \n",
        "                # Make sure dropout and grads are on for training\n",
        "                model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzChxwG3RJ1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "6315633d-3208-43c9-d0df-83c2b6422c43"
      },
      "cell_type": "code",
      "source": [
        "### Train the network \n",
        "train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-65f472a588f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-ae0cbaaefc7f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, testloader, criterion, optimizer, epochs, print_every)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}