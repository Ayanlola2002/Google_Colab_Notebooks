{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save and load PyTorch model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Google_Colab_Notebooks/blob/master/Save_and_load_PyTorch_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2eb-DdE08VLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Created by Paul A. Gureghian on 11/28/18.**\n",
        "\n",
        "**This notebook contains a blueprint for,**\n",
        "\n",
        "**saving and loading PyTorch models.**"
      ]
    },
    {
      "metadata": {
        "id": "AKC699DV7yyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Install CUDA driver\n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1apreKz0G81O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Import packages\n",
        "import torch\n",
        "import fc_model\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import  datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CdYBgalHntu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08AhbiAZHvWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-Jz8p4FHeJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### ### Download and load the testing data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSSBe0QZOJ_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0raUHHkUNzIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "3f19a56e-b0b6-4fea-d0fe-6ee18304602a"
      },
      "cell_type": "code",
      "source": [
        "### View one of the images \n",
        "image, label = next(iter(trainloader))\n",
        "imshow(image[0,:]);"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE5CAYAAADr4VfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njZADYBohB8A0Qg6AaYQcANP+D28+x4Ic7jVAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa165c20a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "krI_0Kh1OoJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Create a network with hyperparams and metrics\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzChxwG3RJ1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "2aa77762-122e-45c0-ce31-6a699a412f48"
      },
      "cell_type": "code",
      "source": [
        "### Train the network \n",
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.695..  Test Loss: 0.995..  Test Accuracy: 0.680\n",
            "Epoch: 1/2..  Training Loss: 1.078..  Test Loss: 0.768..  Test Accuracy: 0.712\n",
            "Epoch: 1/2..  Training Loss: 0.872..  Test Loss: 0.681..  Test Accuracy: 0.745\n",
            "Epoch: 1/2..  Training Loss: 0.806..  Test Loss: 0.666..  Test Accuracy: 0.743\n",
            "Epoch: 1/2..  Training Loss: 0.756..  Test Loss: 0.615..  Test Accuracy: 0.762\n",
            "Epoch: 1/2..  Training Loss: 0.725..  Test Loss: 0.594..  Test Accuracy: 0.770\n",
            "Epoch: 1/2..  Training Loss: 0.691..  Test Loss: 0.593..  Test Accuracy: 0.780\n",
            "Epoch: 1/2..  Training Loss: 0.666..  Test Loss: 0.553..  Test Accuracy: 0.793\n",
            "Epoch: 1/2..  Training Loss: 0.673..  Test Loss: 0.566..  Test Accuracy: 0.792\n",
            "Epoch: 1/2..  Training Loss: 0.661..  Test Loss: 0.560..  Test Accuracy: 0.792\n",
            "Epoch: 1/2..  Training Loss: 0.645..  Test Loss: 0.576..  Test Accuracy: 0.783\n",
            "Epoch: 1/2..  Training Loss: 0.630..  Test Loss: 0.511..  Test Accuracy: 0.814\n",
            "Epoch: 1/2..  Training Loss: 0.637..  Test Loss: 0.511..  Test Accuracy: 0.811\n",
            "Epoch: 1/2..  Training Loss: 0.638..  Test Loss: 0.528..  Test Accuracy: 0.805\n",
            "Epoch: 1/2..  Training Loss: 0.609..  Test Loss: 0.509..  Test Accuracy: 0.807\n",
            "Epoch: 1/2..  Training Loss: 0.528..  Test Loss: 0.497..  Test Accuracy: 0.814\n",
            "Epoch: 1/2..  Training Loss: 0.553..  Test Loss: 0.492..  Test Accuracy: 0.818\n",
            "Epoch: 1/2..  Training Loss: 0.580..  Test Loss: 0.487..  Test Accuracy: 0.826\n",
            "Epoch: 1/2..  Training Loss: 0.577..  Test Loss: 0.492..  Test Accuracy: 0.825\n",
            "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.485..  Test Accuracy: 0.825\n",
            "Epoch: 1/2..  Training Loss: 0.553..  Test Loss: 0.475..  Test Accuracy: 0.828\n",
            "Epoch: 1/2..  Training Loss: 0.563..  Test Loss: 0.489..  Test Accuracy: 0.823\n",
            "Epoch: 1/2..  Training Loss: 0.551..  Test Loss: 0.494..  Test Accuracy: 0.818\n",
            "Epoch: 2/2..  Training Loss: 0.566..  Test Loss: 0.496..  Test Accuracy: 0.818\n",
            "Epoch: 2/2..  Training Loss: 0.554..  Test Loss: 0.483..  Test Accuracy: 0.822\n",
            "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.466..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.481..  Test Accuracy: 0.816\n",
            "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.472..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.522..  Test Loss: 0.486..  Test Accuracy: 0.822\n",
            "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.469..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.543..  Test Loss: 0.469..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.451..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.472..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.466..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.460..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.539..  Test Loss: 0.474..  Test Accuracy: 0.821\n",
            "Epoch: 2/2..  Training Loss: 0.517..  Test Loss: 0.458..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.511..  Test Loss: 0.474..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.447..  Test Accuracy: 0.839\n",
            "Epoch: 2/2..  Training Loss: 0.500..  Test Loss: 0.448..  Test Accuracy: 0.840\n",
            "Epoch: 2/2..  Training Loss: 0.518..  Test Loss: 0.435..  Test Accuracy: 0.841\n",
            "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.443..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.490..  Test Loss: 0.456..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.437..  Test Accuracy: 0.839\n",
            "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.440..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.536..  Test Loss: 0.439..  Test Accuracy: 0.842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MY4lKjRZ1olX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "0021408b-4937-442a-c831-eaca00db40d1"
      },
      "cell_type": "code",
      "source": [
        "### Print the model.state dictionary keys\n",
        "print(\"Model :\\n\", model, '\\n')\n",
        "print(\"The state dict keys:\\n \", model.state_dict().keys())"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model :\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ") \n",
            "\n",
            "The state dict keys:\n",
            "  odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "njqiUxZh3RRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Save the model to a file \n",
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1g6xXpp3pRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ddf0d553-636b-4b1e-e914-8f4eb4aeff03"
      },
      "cell_type": "code",
      "source": [
        "### Load the model from a file \n",
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N2GyzbyK36X8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Load the 'state_dict' into the network\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E4LaFiCP47x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "3b7c46d2-87b2-48da-b7ad-454b1e0c6002"
      },
      "cell_type": "code",
      "source": [
        "### Model architecture must match the checkpoint architecture \n",
        "model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-5530b1a255ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param of torch.Size([400, 784]) from checkpoint, where the shape is torch.Size([512, 784]) in current model.\n\tsize mismatch for hidden_layers.0.bias: copying a param of torch.Size([400]) from checkpoint, where the shape is torch.Size([512]) in current model.\n\tsize mismatch for hidden_layers.1.weight: copying a param of torch.Size([200, 400]) from checkpoint, where the shape is torch.Size([256, 512]) in current model.\n\tsize mismatch for hidden_layers.1.bias: copying a param of torch.Size([200]) from checkpoint, where the shape is torch.Size([256]) in current model.\n\tsize mismatch for hidden_layers.2.weight: copying a param of torch.Size([100, 200]) from checkpoint, where the shape is torch.Size([128, 256]) in current model.\n\tsize mismatch for hidden_layers.2.bias: copying a param of torch.Size([100]) from checkpoint, where the shape is torch.Size([128]) in current model.\n\tsize mismatch for output.weight: copying a param of torch.Size([10, 100]) from checkpoint, where the shape is torch.Size([10, 128]) in current model."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rpKhFIQkGMpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Rebuild the model\n",
        "checkpoint = {'input_size': 784, 'output_size':10, 'hidden_layers': [each.out_features for each in model.hidden_layers], 'state_dict':model.state_dict()}\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBUUay-vKT8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define a function to 'load_checkpoint'\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = fc_model.Network(checkpoint['input_size'],checkpoint['output_size'],checkpoint['hidden_layers'])\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW1BzrbLOQVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Load matched checkpoint architecture \n",
        "model = load_checkpoint('checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}